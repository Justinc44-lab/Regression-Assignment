{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Assignment Questions with Answers\n",
        "\n",
        "# 1. What is Simple Linear Regression\n",
        "A. Simple Linear Regression models the relationship between two variables using a straight line: Y = mX + c.\n",
        "\n",
        "\n",
        "# 2. What are the key assumptions of Simple Linear Regression\n",
        "A. Linearity  \n",
        "B. Independence of errors  \n",
        "C. Homoscedasticity  \n",
        "D. Normality of residuals  \n",
        "\n",
        "\n",
        "# 3. What does the coefficient m represent in the equation Y=mX+c\n",
        "A. The coefficient m represents the slope, indicating how much Y changes for a unit increase in X.\n",
        "\n",
        "\n",
        "# 4. What does the intercept c represent in the equation Y=mX+c\n",
        "A. The intercept c represents the value of Y when X is zero.\n",
        "\n",
        "\n",
        "# 5. How do we calculate the slope m in Simple Linear Regression\n",
        "A. m = (Σ(Xi - X̄)(Yi - Ȳ)) / (Σ(Xi - X̄)^2)\n",
        "\n",
        "\n",
        "# 6. What is the purpose of the least squares method in Simple Linear Regression\n",
        "A. It minimizes the sum of squared residuals to find the best-fitting line.\n",
        "\n",
        "\n",
        "# 7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression\n",
        "A. R² measures how well the independent variable explains the variance in the dependent variable (0 to 1 scale).\n",
        "\n",
        "\n",
        "# 8. What is Multiple Linear Regression\n",
        "A. A regression model with multiple independent variables: Y = b0 + b1X1 + b2X2 + ... + bnXn.\n",
        "\n",
        "\n",
        "# 9. What is the main difference between Simple and Multiple Linear Regression\n",
        "A. Simple regression has one independent variable, while multiple regression has two or more.\n",
        "\n",
        "\n",
        "# 10. What are the key assumptions of Multiple Linear Regression\n",
        "A. Linearity  \n",
        "B. Independence of errors  \n",
        "C. No multicollinearity  \n",
        "D. Homoscedasticity  \n",
        "E. Normality of residuals  \n",
        "\n",
        "\n",
        "# 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\n",
        "A. Heteroscedasticity means non-constant variance in residuals, leading to unreliable standard errors and coefficients.\n",
        "\n",
        "\n",
        "# 12. How can you improve a Multiple Linear Regression model with high multicollinearity\n",
        "A. Remove highly correlated predictors  \n",
        "B. Use Principal Component Analysis (PCA)  \n",
        "C. Use Ridge or Lasso regression  \n",
        "\n",
        "\n",
        "# 13. What are some common techniques for transforming categorical variables for use in regression models\n",
        "A. One-hot encoding  \n",
        "B. Label encoding  \n",
        "C. Ordinal encoding  \n",
        "\n",
        "\n",
        "# 14. What is the role of interaction terms in Multiple Linear Regression\n",
        "A. Interaction terms capture combined effects of two or more variables on the dependent variable.\n",
        "\n",
        "\n",
        "# 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n",
        "A. In multiple regression, the intercept represents Y when all X variables are zero, which may not always be meaningful.\n",
        "\n",
        "\n",
        "# 16. What is the significance of the slope in regression analysis, and how does it affect predictions\n",
        "A. The slope indicates how much the dependent variable changes for a unit change in an independent variable.\n",
        "\n",
        "\n",
        "# 17. How does the intercept in a regression model provide context for the relationship between variables\n",
        "A. It provides a baseline value for Y when the independent variable(s) are zero.\n",
        "\n",
        "\n",
        "# 18. What are the limitations of using R² as a sole measure of model performance\n",
        "A. R² does not indicate causation  \n",
        "B. It does not work well with non-linear relationships  \n",
        "C. High R² may indicate overfitting  \n",
        "\n",
        "\n",
        "# 19. How would you interpret a large standard error for a regression coefficient\n",
        "A. A large standard error suggests high variability in the estimate, making it less reliable.\n",
        "\n",
        "\n",
        "# 20. How can heteroscedasticity be identified in residual plots, and why is it important to address it\n",
        "A. Heteroscedasticity appears as a funnel shape in residual plots. Addressing it ensures reliable statistical inference.\n",
        "\n",
        "\n",
        "# 21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²\n",
        "A. It indicates that adding variables increases R² but does not improve model performance significantly.\n",
        "\n",
        "\n",
        "# 22. Why is it important to scale variables in Multiple Linear Regression\n",
        "A. Scaling ensures that features with different units do not dominate the regression coefficients.\n",
        "\n",
        "\n",
        "# 23. What is polynomial regression\n",
        "A. Polynomial regression models non-linear relationships by adding polynomial terms to the regression equation.\n",
        "\n",
        "\n",
        "# 24. How does polynomial regression differ from linear regression\n",
        "A. Polynomial regression fits a curved line, while linear regression fits a straight line.\n",
        "\n",
        "\n",
        "# 25. When is polynomial regression used\n",
        "A. When data shows a non-linear relationship between independent and dependent variables.\n",
        "\n",
        "\n",
        "# 26. What is the general equation for polynomial regression\n",
        "A. Y = b0 + b1X + b2X² + ... + bnX^n\n",
        "\n",
        "\n",
        "# 27. Can polynomial regression be applied to multiple variables\n",
        "A. Yes, by including polynomial terms for multiple independent variables.\n",
        "\n",
        "\n",
        "# 28. What are the limitations of polynomial regression\n",
        "A. Prone to overfitting  \n",
        "B. Difficult to interpret coefficients  \n",
        "C. Sensitive to outliers  \n",
        "\n",
        "\n",
        "# 29. What methods can be used to evaluate model fit when selecting the degree of a polynomial\n",
        "A. R² and Adjusted R²  \n",
        "B. Cross-validation  \n",
        "C. AIC/BIC (Akaike/Bayesian Information Criterion)  \n",
        "\n",
        "\n",
        "# 30. Why is visualization important in polynomial regression\n",
        "A. It helps identify the appropriate degree of the polynomial and assess model fit.\n",
        "\n",
        "\n",
        "# 31. How is polynomial regression implemented in Python\n",
        "A. Using `PolynomialFeatures` from `sklearn.preprocessing`, followed by fitting a linear regression model.\n"
      ],
      "metadata": {
        "id": "ttVS1zyIDiLx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HpCuYqpoDsKK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}